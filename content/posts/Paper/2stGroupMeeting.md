---
title: "论文笔记"
date: 2025-01-09
tags: [Paper]
description: "记录读过的论文 更新中"
showDate: true
math: true
chordsheet: true
---



## 1 基于驾驶员行为和交通环境构建的拓扑图的驾驶员变道意图预测人机共驾系统

设计了一种基于动态图卷积网络和语义注意力模块（DGCN-SAM）以及自监督引导学习（SGL-YTG）的DLCI预测模型。具体而言，设计 了一种**具有拟人注意力机制的倒置残差模块（IRM-AAM）**，用于提取拓扑图中的重要特征。采用**具有多头自注意力机制的 Transformer** 来捕捉驾驶员头部姿态序列的全局依赖关系。**开发了 DGCN-SAM 来建模图中不同类别或节点之间的关系**。并且**提出了 SGL-UTG  以提高泛化性能**，并在缺乏足够 DLCI 数据的情况下防止过拟合。

**实验数据：**实验平台包含了一个配备六自由度（DOF）运动平台的人机交互驾驶模拟器，以及眼动设备。能够模拟真实的交通和车辆运动。选择20名志愿者参加试验，每位平均1.5个小时完成10公里的不同驾驶场景。将数据集表示为拓扑图，根据拓扑图，设计了一种基于动态图卷积网络(DGCN)与语义注意力模块（SAM）以及基于对拓扑图理解的自监督引导学习（SGL-UTG）的DLCL预测模型。

- 其中具有拟人注意力机制的倒置残差模块用于解决拓扑图的噪声问题，消除无关特征，提高精度。
- 多头注意力机制的 Transformer 模型，通过加权驾驶员头部姿态序列中不同元素的重要性来捕捉长期或全局依赖关系
- 其中动态图卷积网络与语义注意力模块，以拓扑图为输入，该图清晰地描绘了驾驶员行为与驾驶场景关键特征之间的互相作用。DGCN主要解决了如何在拓扑图中有效地、自适应地提取不同特征之间的交互关系。
- 其中SGL-UTG是因为实验数据获得的少，防止过拟合，提高泛化性能。



## 2 基于深度Q学习和请求 - 响应机制的变道系统

本研究构建了一个将交通车道离散化为单元格的变道模型，同时考虑了强制变道和自主变道操作，并提出了一种**基于带有请求-响应机制的深度Q网络**的新方法。所构建的变道系统被划分为孤立组和对称组，然后将独立的 Q 学习和“中央代理”的概念相结合，以简化训练过程。在所提出的方法中，这些组可以分为两类：请求组和响应组。在训练过程中，请求组和响应组分别进行训练。具体而言，请求组仅考虑组内的状态来训练代理，而响应组除了考虑组内的状态外，还评估来自请求组的叠加动作（即请求消息）。执行过程也以与训练过程相同的去中心化方式处理。然后，将基于规则的方法、基于博弈论的分解算法和简单的深度 Q 学习方法等基准方法与所提出的方法进行了比较。（实验输入数据为模拟数据 随机生成）

> 为什么提出这个方法？

1. **交通拥堵问题**：随着车辆出行需求的增加，交通拥堵问题日益严重，传统的变道控制方法在拥堵环境中表现不佳，无法有效调节交通流量。
2. **现有方法的局限性**：
   - **基于规则的方法**：在交通拥堵时效率低下，无法为车辆提供足够的变道空间。
   - **基于博弈论的方法**：随着参与者数量的增加，计算复杂度呈指数增长，计算时间过长。
   - **基于深度强化学习的方法**：虽然训练完成后执行时间较短，但大多数研究仅考虑单智能体系统，无法应对多车辆同时变道的复杂场景。

> 解决了什么问题？

**变道效率**：在拥堵的交通环境中，优化多车辆的变道操作，提高变道效率。

**计算复杂度**：减少变道系统的计算时间，尤其是在交通拥堵的情况下。

**多智能体协作**：解决多车辆同时变道时的协作问题，确保车辆能够高效、安全地完成变道操作。



## 3* 基于深度强化学习的自主车道变道速度控制对混合车辆组水平的研究

提出一种基于深度强化学习的编导模型，用于训练自动驾驶车辆在与不同人类驾驶行为的交互中完成变道。首先，从自然行驶轨迹中提取周围车辆的轨迹，构建了一个车辆群体级的混合流换道环境。然后，**确定状态空间和动作空间，设计奖励函数，综合考虑安全性和效率性，引导自主车辆不发生碰撞，确定加速度和方向角完成换道行为，并在该方法中融入避碰策略，保证纵向运动的安全性**。此外，训练后的模型可以学习成功换道的经验，导致在测试中无碰撞的成功率达到90%。最后，从安全性和效率评价指标两个方面对所提方法的行驶性能进行了分析，证明了所提方法能够提高换道过程的效率和安全性。使用highD数据集。

本研究中的混合流中的自主换道框架由两部分组成：混合流中的换道环境和基于SAC的控制。

- **用马尔可夫决策过程（MDP）建模变道问题**，定义**状态空间、动作空间、状态转移和奖励函数**，让问题符合强化学习的框架。

  **用深度强化学习（SAC算法）来优化变道策略**，让自主车辆在混合车流环境中通过**试错学习（trial-and-error learning）**，不断调整加速度和方向角，以安全高效地完成变道。

本研究**解决了当前变道建模的几个关键问题**：

1. 传统数值模型难以**充分描述人类驾驶行为的多样性和复杂性**，导致模拟环境中的变道决策适应性较差。
2. 数据驱动方法虽然能模仿人类驾驶行为，但**缺乏对优劣驾驶行为的区分能力**，无法主动优化决策。
3. 本研究通过引入**深度强化学习**，使自主车辆能够通过**试错学习**不断优化变道策略，提高变道的**安全性和效率**。



## 4 考虑对向车流的变道意图识别：深度学习进展揭示的新见解

本研究采用**基于Transformer的深度学习方法**进行**变道意图识别**。但是其中使用到了**Logitech模拟驾驶座舱**和**Tobii Pro Glasses3眼动追踪设备**，采集驾驶员眼动数据、车辆运动数据等信息。这篇论文的**主要创新点**就在于**眼动追踪数据的引入**和**LIME解释模型的使用**。所以和第一篇论文一样有局限性。



## 5 

本研究提出了一种**融合驾驶风格和车辆动力学的变道轨迹预测方法**，采用**深度学习与概率建模结合**的方式来提高预测准确性。（highD数据集，将数据集分为 **80%训练集 + 20%测试集**）主要方法包括：

1. **Attention-LSTM 变道行为识别模型**
   - 结合**注意力机制（Attention Mechanism）**，提取车辆之间的交互特征，提高变道行为识别的准确性。
   - 该模型能够从历史轨迹中学习驾驶风格，并对变道行为进行分类。
2. **高斯过程运动建模轨迹预测（GPMM-TP）**
   - 采用**高斯过程（Gaussian Process, GP）对变道轨迹进行建模，引入轨迹不确定性**。
   - 通过**高斯混合模型（GMM）对不同驾驶风格进行聚类，并使用结构相似性匹配**来选择最符合当前车辆行为的轨迹模式。
3. **交互多模型（IMM）算法**
   - 结合**CTRV（Constant Turn Rate and Velocity）运动模型**，基于**扩展卡尔曼滤波（EKF）**进行短期预测（CTEKF-TP）。
   - 通过IMM算法，动态分配GPMM-TP和CTEKF-TP的权重，使得预测方法兼顾短期和长期精度。

**方法论的实现：**

1. **变道行为识别（Attention-LSTM）**
   - 输入：车辆的历史轨迹（横纵向位置、速度、加速度、yaw角等）及周围车辆的相对位置。
   - 处理：LSTM 提取时序特征，Attention 机制筛选关键特征，最终分类变道行为（如保持车道、左变道、右变道）。
   - 结果：提升变道识别的准确性，提供行为先验信息。
2. **轨迹建模与预测（GPMM-TP）**
   - 先使用**高斯混合模型（GMM）**聚类不同驾驶风格（温和、正常、激进）。
   - 计算历史轨迹与原型轨迹的**结构相似性**，选取最匹配的轨迹模式。
   - 采用**高斯过程**进行轨迹预测，并估计预测的不确定性范围。
3. **融合短期与长期预测（IMM-TP）**
   - 短期：CTEKF-TP基于**车辆动力学**进行预测。
   - 长期：GPMM-TP基于**驾驶风格与轨迹模式**进行预测。
   - IMM动态调整两者的权重，提高整体预测性能。

---



驾驶风格分类 → 换道意图识别 → 风险评估 → 轨迹预测

1. 驾驶风格分类

   选择数据集highD / NGSIM，包含车辆类型信息。通过聚类算法GMM / K-Means。

2. 换道意图识别

   采用Graph Attention Network（GAT图注意力网络）建立车辆交互模型，节点：每辆车，边：车辆间的相对关系。训练GNN 模型去预测换道意图概率。关注激进 / 轿车驾驶风格车辆是否更容易发生变道。

3. 风险评估FTA / SHAP / UQ 

   结合 GNN 计算的**换道意图概率**，使用**故障树分析法（FTA）**分析可能发生风险的原因。

4. 轨迹预测

   

   
